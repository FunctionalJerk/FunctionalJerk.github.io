---
layout: post
title: 'VocalSampler'
---

# tSNE-VocalSampler

<video width="100%" height="336" controls>
  <source src="{{ site.url }}/assets/vid/projects/{{page.title}}/demo.mp4" type="video/mp4">
</video>  

Samples within a library were analyzed and mapped by the *t-SNE algorithm* as described [here]({{ site.url }}/projects/DataMining). 
This produces a 2D-Scatterplot where each point represents a vocal-sample. 
These samples can now be sequenced and resynthesized live, through a gui that was programmed in *SuperCollider[^sc]*.

In this project I aimed to connect the results of my artistic research on vocal melodies and on mining audio-data. 
It was part of my bachelor studies in *Music and Media* at *Robert-Schumann-Hochschule Düsseldorf*.  
For further information, please refer to this project's [GitHub-repostitory](https://github.com/FunctionalJerk/tSNE-VocalSampler).  


---
* nessecary line
{:footnotes}

[^sc]: [supercollider.github.io](https://supercollider.github.io/)

# Related projects: 

- [Audio Data Mining]({{ site.url }}/projects/DataMining)
- [°mm ↓m​:​°​,]({{ site.url }}/projects/mm-m)
